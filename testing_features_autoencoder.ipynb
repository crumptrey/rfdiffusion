{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.2) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from audio_encoders_pytorch.audio_encoders_pytorch import AutoEncoder1d, STFT, Bottleneck, VariationalBottleneck\n",
    "import utils.load_datasets\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator\n",
    "import random\n",
    "import optuna\n",
    "from torch.utils.data import random_split\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from einops import rearrange\n",
    "class STFTAutoEncoder1d(AutoEncoder1d):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        channels: int,\n",
    "        multipliers: Sequence[int],\n",
    "        factors: Sequence[int],\n",
    "        num_blocks: Sequence[int],\n",
    "        resnet_groups: int = 8,\n",
    "        stft_num_fft: int = 1024,\n",
    "        stft_hop_length: int = 256,\n",
    "        stft_win_length: Optional[int] = None,\n",
    "        bottleneck: Union[Bottleneck, List[Bottleneck]] = [],\n",
    "        bottleneck_channels: Optional[int] = None,\n",
    "    ):\n",
    "        self.frequency_channels = stft_num_fft // 2 + 1\n",
    "        super().__init__(\n",
    "            in_channels=in_channels * self.frequency_channels * 2,  # Real and imaginary parts\n",
    "            channels=channels,\n",
    "            multipliers=multipliers,\n",
    "            factors=factors,\n",
    "            num_blocks=num_blocks,\n",
    "            resnet_groups=resnet_groups,\n",
    "            bottleneck=bottleneck,\n",
    "            bottleneck_channels=bottleneck_channels,\n",
    "        )\n",
    "        self.stft = STFT(\n",
    "            num_fft=stft_num_fft,\n",
    "            hop_length=stft_hop_length,\n",
    "            window_length=stft_win_length,\n",
    "            use_complex=False,\n",
    "        )\n",
    "\n",
    "    def encode(self, x: Tensor, with_info: bool = False) -> Union[Tensor, Tuple[Tensor, Any]]:\n",
    "        stft_real, stft_imag = self.stft.encode(x)\n",
    "        stft_combined = torch.cat([stft_real, stft_imag], dim=1)\n",
    "        stft_flat = rearrange(stft_combined, \"b c f l -> b (c f) l\")\n",
    "        return super().encode(stft_flat, with_info=with_info)\n",
    "\n",
    "    def decode(self, z: Tensor, with_info: bool = False) -> Union[Tensor, Tuple[Tensor, Any]]:\n",
    "        stft_flat, info = super().decode(z, with_info=True)\n",
    "        stft_combined = rearrange(stft_flat, \"b (c f) l -> b c f l\", f=self.frequency_channels)\n",
    "        stft_real, stft_imag = stft_combined.chunk(2, dim=1)\n",
    "        waveform = self.stft.decode(stft_real, stft_imag)\n",
    "        return (waveform, info) if with_info else waveform\n",
    "\n",
    "    def forward(self, x: Tensor, with_info: bool = False) -> Union[Tensor, Tuple[Tensor, Any]]:\n",
    "        z, info_encoder = self.encode(x, with_info=True)\n",
    "        y, info_decoder = self.decode(z, with_info=True)\n",
    "        info = {\n",
    "            **dict(latent=z),\n",
    "            **prefix_dict(\"encoder_\", info_encoder),\n",
    "            **prefix_dict(\"decoder_\", info_decoder),\n",
    "        }\n",
    "        return (y, info) if with_info else y\n",
    "\n",
    "    def loss(self, x: Tensor, with_info: bool = False) -> Union[Tensor, Tuple[Tensor, Dict]]:\n",
    "        y, info = self(x, with_info=True)\n",
    "        loss = F.mse_loss(x, y)\n",
    "        return (loss, info) if with_info else loss\n",
    "    \n",
    "stft_autoencoder = STFTAutoEncoder1d(\n",
    "    in_channels=2,  # Assuming mono audio\n",
    "    channels=64,\n",
    "    multipliers=[1, 2, 4, 8],\n",
    "    factors=[4, 4, 2],\n",
    "    num_blocks=[2, 2, 2],\n",
    "    stft_num_fft=1024,\n",
    "    stft_hop_length=256,\n",
    "    bottleneck=[VariationalBottleneck(channels=512)],  # Optional: add a variational bottleneck\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c7df77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pzlpjgta) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf10b2b8a4b4c1e83580e57a520d768"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">73535</strong> at: <a href='https://wandb.ai/trey-crump-yale-university/autoencoder_feature/runs/pzlpjgta' target=\"_blank\">https://wandb.ai/trey-crump-yale-university/autoencoder_feature/runs/pzlpjgta</a><br/> View project at: <a href='https://wandb.ai/trey-crump-yale-university/autoencoder_feature' target=\"_blank\">https://wandb.ai/trey-crump-yale-university/autoencoder_feature</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240815_120628-pzlpjgta/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pzlpjgta). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/ext/trey/experiment_diffusion/experiment_rfdiffusion/wandb/run-20240815_120833-x3e0evi4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/trey-crump-yale-university/autoencoder_feature/runs/x3e0evi4' target=\"_blank\">342919</a></strong> to <a href='https://wandb.ai/trey-crump-yale-university/autoencoder_feature' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/trey-crump-yale-university/autoencoder_feature' target=\"_blank\">https://wandb.ai/trey-crump-yale-university/autoencoder_feature</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/trey-crump-yale-university/autoencoder_feature/runs/x3e0evi4' target=\"_blank\">https://wandb.ai/trey-crump-yale-university/autoencoder_feature/runs/x3e0evi4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1 GPUs\n",
      "Number of parameters: 24391500\n",
      "Models will be saved in: /home/trey/experiment_rfdiffusion/models/rfdiffusion_diffusion/autoencoder_feature\n",
      "79880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                                                                                                                               | 0/79880 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "istft requires a complex-valued input tensor matching the output from stft with return_complex=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_434241/888497658.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_434241/888497658.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Models will be saved in: {config['model_save_dir']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_434241/888497658.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, scheduler, train_loader, val_loader, accelerator, config)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_434241/1716369992.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, with_info)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         info = {\n\u001b[1;32m     68\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_434241/1716369992.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z, with_info)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mstft_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b (c f) l -> b c f l\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrequency_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mstft_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft_imag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstft_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft_imag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_info\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mwaveform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext/trey/experiment_diffusion/experiment_rfdiffusion/audio_encoders_pytorch/audio_encoders_pytorch/modules.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, stft_a, stft_b)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mstft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         wave = torch.istft(\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mstft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: istft requires a complex-valued input tensor matching the output from stft with return_complex=True."
     ]
    }
   ],
   "source": [
    "def setup_training(config, model):\n",
    "    optimizer = Adam(model.parameters(), lr=config['learning_rate'], betas=tuple(config['adam_betas']))\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, config['gamma'])\n",
    "    return optimizer, criterion, scheduler\n",
    "\n",
    "\n",
    "\n",
    "def setup_dataloader(batch_size, num_workers, val_split=0.2):\n",
    "    dataset = utils.load_datasets.DeepSig2018Dataset(\n",
    "        \"/ext/trey/experiment_diffusion/experiment_rfdiffusion/dataset/GOLD_XYZ_OSC.0001_1024.hdf5\")\n",
    "    val_size = int(len(dataset) * val_split)\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                              num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def evaluate_model(model, data_loader, accelerator):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in data_loader:\n",
    "            x = x.to(accelerator.device)\n",
    "            y = model.encode(x)\n",
    "            y = model.decode(y)\n",
    "            loss = torch.nn.functional.mse_loss(y, x)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            num_samples += x.size(0)\n",
    "\n",
    "    avg_loss = total_loss / num_samples\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def setup_accelerator(config):\n",
    "    accelerator = Accelerator(log_with=\"wandb\")\n",
    "    run_name = str(random.randint(0, 10e5))\n",
    "    accelerator.init_trackers(\n",
    "        config['project_name'],\n",
    "        config=config,\n",
    "        init_kwargs={\"wandb\": {\"name\": run_name}}\n",
    "    )\n",
    "    return accelerator, run_name\n",
    "\n",
    "def train_model(model, optimizer, criterion, scheduler, train_loader, val_loader, accelerator, config):\n",
    "    model, optimizer, train_loader, val_loader, scheduler = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader, scheduler\n",
    "    )\n",
    "    num_training_steps = config['epochs'] * len(train_loader)\n",
    "    print(num_training_steps)\n",
    "    progress_bar = tqdm(range(num_training_steps), disable=not accelerator.is_local_main_process)\n",
    "\n",
    "    model.train()\n",
    "    step = 1\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        for x, _ in train_loader:\n",
    "            y = model(x)\n",
    "            loss = criterion(y, x)\n",
    "\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            accelerator.log({\"training_loss\": loss, \"learning_rate\": scheduler.get_last_lr()[0]}, step=step)\n",
    "            step += 1\n",
    "\n",
    "        if epoch % config['save_every'] == 0 and accelerator.is_main_process:\n",
    "            save_checkpoint(accelerator.unwrap_model(model), optimizer, epoch, config['model_save_dir'], f'model_epoch_{epoch}.pth')\n",
    "            validation_loss = evaluate_model(model, val_loader, accelerator)\n",
    "            wandb.log({\"validation_loss\": validation_loss})\n",
    "\n",
    "    accelerator.end_training()\n",
    "    \n",
    "def save_checkpoint(model, optimizer, epoch, save_dir, filename):\n",
    "    checkpoint_path = os.path.join(save_dir, filename)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "def main():\n",
    "    config = {\n",
    "        'learning_rate':1e4,\n",
    "        'epochs':10,\n",
    "        'project_name':'autoencoder_feature',\n",
    "        'adam_betas':(0.9,0.999),\n",
    "        'gamma':0.9,\n",
    "        'base_save_dir': \"/home/trey/experiment_rfdiffusion/models/rfdiffusion_diffusion\",\n",
    "        'num_workers':8\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Construct model_save_dir\n",
    "    config['model_save_dir'] = os.path.join(config['base_save_dir'], config['project_name'])\n",
    "    os.makedirs(config['model_save_dir'], exist_ok=True)\n",
    "\n",
    "    accelerator, run_name = setup_accelerator(config)\n",
    "\n",
    "    model = STFTAutoEncoder1d(\n",
    "    in_channels=2,  # Assuming mono audio\n",
    "    channels=64,\n",
    "    multipliers=[1, 2, 4, 8],\n",
    "    factors=[4, 4, 2],\n",
    "    num_blocks=[2, 2, 2],\n",
    "    stft_num_fft=1024,\n",
    "    stft_hop_length=256,\n",
    "    bottleneck=[VariationalBottleneck(channels=512)],  # Optional: add a variational bottleneck\n",
    "    )\n",
    "    optimizer, criterion, scheduler = setup_training(config, model)\n",
    "    train_loader, val_loader = setup_dataloader(256,8)\n",
    "\n",
    "\n",
    "    print(f\"Training on {accelerator.num_processes} GPUs\")\n",
    "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "    print(f\"Models will be saved in: {config['model_save_dir']}\")\n",
    "\n",
    "    train_model(model, optimizer, criterion, scheduler, train_loader, val_loader, accelerator, config)\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        final_checkpoint_path = os.path.join(config['model_save_dir'], f'model_{run_name}.pth')\n",
    "        save_checkpoint(accelerator.unwrap_model(model), optimizer, config['epochs'], config['model_save_dir'],\n",
    "                        final_checkpoint_path)\n",
    "\n",
    "    print(\"Training complete and models saved.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b717b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f590d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
